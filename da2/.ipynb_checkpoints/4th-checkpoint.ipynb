{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "url1 = \"https://en.wikipedia.org/wiki/Web_mining\"\n",
    "url2 = \"https://en.wikipedia.org/wiki/Data_mining\"\n",
    "url3 = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "url4 = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "url5 = \"https://en.wikipedia.org/wiki/Mining\"\n",
    "html1 = urllib.request.urlopen(url1).read().decode('utf8')\n",
    "html2 = urllib.request.urlopen(url2).read().decode('utf8')\n",
    "html3 = urllib.request.urlopen(url1).read().decode('utf8')\n",
    "html4 = urllib.request.urlopen(url1).read().decode('utf8')\n",
    "html5 = urllib.request.urlopen(url1).read().decode('utf8')\n",
    "raw1 = BeautifulSoup(html1, 'html.parser').get_text()\n",
    "raw2 = BeautifulSoup(html2, 'html.parser').get_text()\n",
    "raw3 = BeautifulSoup(html3, 'html.parser').get_text()\n",
    "raw4 = BeautifulSoup(html4, 'html.parser').get_text()\n",
    "raw5 = BeautifulSoup(html5, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('.')\n",
    "stop_words.append(')')\n",
    "stop_words.append('(')\n",
    "stop_words.append(';')\n",
    "stop_words.append(',')\n",
    "stop_words.append('')\n",
    "stop_words.append('[')\n",
    "stop_words.append(']')\n",
    "stop_words.append(':')\n",
    "stop_words.append('-')\n",
    "stop_words.append('^')\n",
    "stop_words.append('=')\n",
    "stop_words.append('+')\n",
    "stop_words.append('*')\n",
    "stop_words.append('~')\n",
    "stop_words.append('`')\n",
    "stop_words.append('<')\n",
    "stop_words.append('>')\n",
    "stop_words.append('!')\n",
    "stop_words.append('_')\n",
    "stop_words.append('#')\n",
    "stop_words.append('@')\n",
    "stop_words.append('%')\n",
    "stop_words.append(\"'s\")\n",
    "stop_words.append(\"'re\")\n",
    "word_tokens1 = word_tokenize(raw1)\n",
    "word_tokens2 = word_tokenize(raw2)\n",
    "word_tokens3 = word_tokenize(raw3)\n",
    "word_tokens4 = word_tokenize(raw4)\n",
    "word_tokens5 = word_tokenize(raw5)\n",
    "filtered_words1 = [w for w in word_tokens1 if not w in stop_words]\n",
    "filtered_words2 = [w for w in word_tokens2 if not w in stop_words]\n",
    "filtered_words3 = [w for w in word_tokens3 if not w in stop_words]\n",
    "filtered_words4 = [w for w in word_tokens4 if not w in stop_words]\n",
    "filtered_words5 = [w for w in word_tokens5 if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = []\n",
    "for w in filtered_words1:\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "for w in filtered_words2:\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "for w in filtered_words3:\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "for w in filtered_words4:\n",
    "    w = lemmatizer.lemmatize(w)\n",
    "for w in filtered_words5:\n",
    "    w = lemmatizer.lemmatize(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "2801 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    496\u001b[0m         result = _convert_object_array(\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    580\u001b[0m             raise AssertionError(\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m                 \u001b[1;34mf\"{len(content)} columns\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 2801 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a49c15cf0cf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mdoc5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistOfWords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bag Of Words Model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 2801 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "set1 = set(filtered_words1)\n",
    "set2 = set(filtered_words2)\n",
    "set3 = set(filtered_words3)\n",
    "set4 = set(filtered_words4)\n",
    "set5 = set(filtered_words5)\n",
    "totalSet = set1|set2|set3|set4|set5\n",
    "totalList = list(totalSet)\n",
    "listOfWords = ['Document ID']\n",
    "for i in range(len(totalList)):\n",
    "    listOfWords.append(totalList[i])\n",
    "doc1 = ['doc1']\n",
    "doc2 = ['doc2']\n",
    "doc3 = ['doc3']\n",
    "doc4 = ['doc4']\n",
    "doc5 = ['doc5']\n",
    "for w in listOfWords:\n",
    "    if(w == \"Document ID\"):\n",
    "        continue\n",
    "    if (w in filtered_words1):\n",
    "        doc1.append(filtered_words1.count(w))\n",
    "    else:\n",
    "        doc1.append(0)\n",
    "    if (w in filtered_words2):\n",
    "        doc2.append(filtered_words2.count(w))\n",
    "    else:\n",
    "        doc2.append(0)\n",
    "    if (w in filtered_words3):\n",
    "        doc3.append(filtered_words3.count(w))\n",
    "    else:\n",
    "        doc3.append(0)\n",
    "    if (w in filtered_words4):\n",
    "        doc4.append(filtered_words4.count(w))\n",
    "    else:\n",
    "        doc4.append(0)\n",
    "    if(w in filtered_words5):\n",
    "        doc5.append(filtered_words5.count(w))\n",
    "    else:\n",
    "        doc5.append(0)\n",
    "data = [doc1,doc2,doc3,doc4,doc5]\n",
    "df = pd.DataFrame(data, columns = listOfWords)\n",
    "print(\"Bag Of Words Model\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>reported</th>\n",
       "      <th>exception</th>\n",
       "      <th>stalled</th>\n",
       "      <th>exchange</th>\n",
       "      <th>2014-01-27</th>\n",
       "      <th>Browsing</th>\n",
       "      <th>of—the</th>\n",
       "      <th>SIGMOD</th>\n",
       "      <th>instead</th>\n",
       "      <th>...</th>\n",
       "      <th>vision</th>\n",
       "      <th>Image</th>\n",
       "      <th>utilized</th>\n",
       "      <th>effort</th>\n",
       "      <th>title=Web_mining</th>\n",
       "      <th>judging</th>\n",
       "      <th>exists</th>\n",
       "      <th>informationCite</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Studies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document ID  reported  exception  stalled  exchange  2014-01-27  Browsing  \\\n",
       "0        doc1         0          0        0         0           0         2   \n",
       "1        doc2         1          3        1         1           1         0   \n",
       "2        doc3         0          0        0         0           0         2   \n",
       "3        doc4         0          0        0         0           0         2   \n",
       "4        doc5         0          0        0         0           0         2   \n",
       "\n",
       "   of—the  SIGMOD  instead  ...  vision  Image  utilized  effort  \\\n",
       "0       0       0        1  ...       0      0         1       1   \n",
       "1       1       1        0  ...       1      2         0       0   \n",
       "2       0       0        1  ...       0      0         1       1   \n",
       "3       0       0        1  ...       0      0         1       1   \n",
       "4       0       0        1  ...       0      0         1       1   \n",
       "\n",
       "   title=Web_mining  judging  exists  informationCite  1.0  Studies  \n",
       "0                 1        2       0                1    0        1  \n",
       "1                 0        0       1                1    2        1  \n",
       "2                 1        2       0                1    0        1  \n",
       "3                 1        2       0                1    0        1  \n",
       "4                 1        2       0                1    0        1  \n",
       "\n",
       "[5 rows x 2801 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
